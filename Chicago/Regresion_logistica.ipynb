{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "import scipy.optimize as curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8269 entries, 0 to 8268\n",
      "Data columns (total 50 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   host_name                    8269 non-null   object \n",
      " 1   host_since                   8269 non-null   object \n",
      " 2   host_location                8269 non-null   object \n",
      " 3   host_response_time           8269 non-null   object \n",
      " 4   host_response_rate           8269 non-null   object \n",
      " 5   host_is_superhost            8269 non-null   object \n",
      " 6   host_neighbourhood           8269 non-null   object \n",
      " 7   host_verifications           8269 non-null   object \n",
      " 8   host_has_profile_pic         8269 non-null   object \n",
      " 9   host_identity_verified       8269 non-null   object \n",
      " 10  neighbourhood                8269 non-null   object \n",
      " 11  neighbourhood_cleansed       8269 non-null   object \n",
      " 12  property_type                8269 non-null   object \n",
      " 13  room_type                    8269 non-null   object \n",
      " 14  bathrooms_text               8269 non-null   object \n",
      " 15  amenities                    8269 non-null   object \n",
      " 16  has_availability             8269 non-null   object \n",
      " 17  first_review                 8269 non-null   object \n",
      " 18  last_review                  8269 non-null   object \n",
      " 19  license                      8269 non-null   object \n",
      " 20  instant_bookable             8269 non-null   object \n",
      " 21  host_id                      8269 non-null   int64  \n",
      " 22  host_acceptance_rate         8269 non-null   float64\n",
      " 23  host_total_listings_count    8269 non-null   float64\n",
      " 24  latitude                     8269 non-null   float64\n",
      " 25  longitude                    8269 non-null   float64\n",
      " 26  accommodates                 8269 non-null   float64\n",
      " 27  bathrooms                    8269 non-null   float64\n",
      " 28  bedrooms                     8269 non-null   float64\n",
      " 29  beds                         8269 non-null   float64\n",
      " 30  price                        8269 non-null   float64\n",
      " 31  minimum_nights               8269 non-null   float64\n",
      " 32  maximum_nights               8269 non-null   int64  \n",
      " 33  minimum_nights_avg_ntm       8269 non-null   float64\n",
      " 34  maximum_nights_avg_ntm       8269 non-null   float64\n",
      " 35  availability_30              8269 non-null   int64  \n",
      " 36  availability_60              8269 non-null   int64  \n",
      " 37  availability_90              8269 non-null   int64  \n",
      " 38  availability_365             8269 non-null   int64  \n",
      " 39  number_of_reviews            8269 non-null   float64\n",
      " 40  number_of_reviews_ltm        8269 non-null   float64\n",
      " 41  number_of_reviews_l30d       8269 non-null   float64\n",
      " 42  review_scores_rating         8269 non-null   float64\n",
      " 43  review_scores_accuracy       8269 non-null   float64\n",
      " 44  review_scores_cleanliness    8269 non-null   float64\n",
      " 45  review_scores_checkin        8269 non-null   float64\n",
      " 46  review_scores_communication  8269 non-null   float64\n",
      " 47  review_scores_location       8269 non-null   float64\n",
      " 48  review_scores_value          8269 non-null   float64\n",
      " 49  reviews_per_month            8269 non-null   float64\n",
      "dtypes: float64(23), int64(6), object(21)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Cargar archivo csv\n",
    "df = pd.read_csv('50_sin_nulos_ni_atipicos_Chicago_Illinois_UnitedStates.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remplazar valores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f' 't']\n",
      "['f' 't']\n",
      "['f' 't']\n",
      "['Entire rental unit' 'Other property']\n",
      "['Entire home/apt' 'Other room']\n",
      "['f' 't']\n",
      "['Chicago, IL' 'Other location']\n",
      "['More than one hour' 'within an hour']\n",
      "[0. 2.]\n",
      "['f' 't']\n"
     ]
    }
   ],
   "source": [
    "#Verificar los valores sin repertirse de una columna\n",
    "unico1 = np.unique(df['host_is_superhost'])\n",
    "unico2 = np.unique(df['has_availability'])\n",
    "unico3 = np.unique(df['instant_bookable'])\n",
    "unico4 = np.unique(df['property_type'])\n",
    "unico5 = np.unique(df['room_type'])\n",
    "unico6 = np.unique(df['host_identity_verified'])\n",
    "unico7 = np.unique(df['host_location'])\n",
    "unico8 = np.unique(df['host_response_time'])\n",
    "unico9 = np.unique(df['bedrooms'])\n",
    "unico10 = np.unique(df['host_has_profile_pic'])\n",
    "print(unico1)\n",
    "print(unico2)\n",
    "print(unico3)\n",
    "print(unico4)\n",
    "print(unico5)\n",
    "print(unico6)\n",
    "print(unico7)\n",
    "print(unico8)\n",
    "print(unico9)\n",
    "print(unico10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierto  una variable a dicotomica\n",
    "df['host_is_superhost'] =df['host_is_superhost'].replace([\"Unknown\"], \"f\")\n",
    "df['has_availability'] =df['has_availability'].replace([\"Unknown\"], \"f\")\n",
    "#df['instant_bookable'] =df['instant_bookable'].replace([\"Unknown\"], \"f\")\n",
    "df['property_type'] = df['property_type'].mask(df['property_type'] != \"Entire rental unit\", \"Other property\")\n",
    "df['room_type'] =df['room_type'].replace([\"Hotel room\", \"Private room\", \"Shared room\"], \"Other room\")\n",
    "#df['host_identity_verified'] =df['host_identity_verified'].replace([\"Unknown\"], \"f\")\n",
    "df['host_location'] =df['host_location'].mask(df['host_location'] != \"Chicago, IL\", \"Other location\")\n",
    "df['host_response_time'] =df['host_response_time'].replace([\"Not defined\", \"a few days or more\", \"within a day\", \"within a few hours\"], \"More than one hour\")\n",
    "df['bedrooms'] =df['bedrooms'].replace([1, 1.5, 3], 0)\n",
    "#df['host_has_profile_pic'] =df['host_has_profile_pic'].replace([\"Unknown\"], \"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corroboramos valores nulos\n",
    "valores_nulos = df.isnull().sum().sum()\n",
    "valores_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion host_is_superhost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[992 410]\n",
      " [485 594]]\n",
      "Precision del modelo:  0.5916334661354582\n",
      "Exactitud del modelo:  0.6392583635630794\n",
      "Sensibilidad del modelo:  0.5505097312326228\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication']] #Numericas\n",
    "Var_Dep = df['host_is_superhost'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion has_availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[   0   17]\n",
      " [   0 2464]]\n",
      "Precision del modelo:  0.9931479242241031\n",
      "Exactitud del modelo:  0.9931479242241031\n",
      "Sensibilidad del modelo:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['availability_30', 'availability_60', 'availability_90']] #Numericas\n",
    "Var_Dep = df['has_availability'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion instant_bookable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[1483   91]\n",
      " [ 807  100]]\n",
      "Precision del modelo:  0.5235602094240838\n",
      "Exactitud del modelo:  0.638049173720274\n",
      "Sensibilidad del modelo:  0.11025358324145534\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['host_acceptance_rate', 'price', 'availability_365']] #Numericas\n",
    "Var_Dep = df['instant_bookable'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion property_type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[801 527]\n",
      " [583 570]]\n",
      "Precision del modelo:  0.578757225433526\n",
      "Exactitud del modelo:  0.5525997581620314\n",
      "Sensibilidad del modelo:  0.6031626506024096\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['review_scores_location', 'accommodates', 'price']] #Numericas\n",
    "Var_Dep = df['property_type'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire rental unit\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire rental unit\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion room_type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[1863   48]\n",
      " [ 264  306]]\n",
      "Precision del modelo:  0.8758815232722144\n",
      "Exactitud del modelo:  0.8742442563482467\n",
      "Sensibilidad del modelo:  0.9748822605965463\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['price', 'accommodates', 'bathrooms']] #Numericas\n",
    "Var_Dep = df['room_type'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire home/apt\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Entire home/apt\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion host_identity_verified**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[   0  240]\n",
      " [   0 2241]]\n",
      "Precision del modelo:  0.9032648125755743\n",
      "Exactitud del modelo:  0.9032648125755743\n",
      "Sensibilidad del modelo:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['review_scores_value', 'host_total_listings_count', 'number_of_reviews']] #Numericas\n",
    "Var_Dep = df['host_identity_verified'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion host_location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[1632    0]\n",
      " [ 849    0]]\n",
      "Precision del modelo:  0.6577992744860943\n",
      "Exactitud del modelo:  0.6577992744860943\n",
      "Sensibilidad del modelo:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['review_scores_communication', 'review_scores_location', 'review_scores_cleanliness']] #Numericas\n",
    "Var_Dep = df['host_location'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Chicago, IL\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Chicago, IL\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion host_response_time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[   0  438]\n",
      " [   0 2043]]\n",
      "Precision del modelo:  0.8234582829504232\n",
      "Exactitud del modelo:  0.8234582829504232\n",
      "Sensibilidad del modelo:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['review_scores_communication', 'review_scores_value', 'price']] #Numericas\n",
    "Var_Dep = df['host_response_time'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"within an hour\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"within an hour\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion bedrooms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[1802   38]\n",
      " [ 640    1]]\n",
      "Precision del modelo:  0.02564102564102564\n",
      "Exactitud del modelo:  0.7267230955259976\n",
      "Sensibilidad del modelo:  0.0015600624024961\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['accommodates', 'bathrooms', 'price']] #Numericas\n",
    "Var_Dep = df['bedrooms'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=2)\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=2)\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediccion host_has_profile_pic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion: \n",
      "[[   0   40]\n",
      " [   0 2441]]\n",
      "Precision del modelo:  0.9838774687625957\n",
      "Exactitud del modelo:  0.9838774687625957\n",
      "Sensibilidad del modelo:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e idependientes para la regresion logistica\n",
    "Vars_Indep = df[['review_scores_communication', 'review_scores_value', 'reviews_per_month']] #Numericas\n",
    "Var_Dep = df['host_has_profile_pic'] #Dicotomica\n",
    "#Redefinimos las variables\n",
    "X = Vars_Indep\n",
    "y = Var_Dep\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size= 0.3, random_state=None)\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "#Para realizar el escalamiento de las variables \"X\" tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "#Entrenamos al modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "#Realizamos una prediccion\n",
    "y_pred = algoritmo.predict(X_test)\n",
    "#Verifico la matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusion: ')\n",
    "print(matriz)\n",
    "#Calculo la precision del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precision del modelo: ', precision)\n",
    "#Calculamos la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo: ', exactitud)\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print(\"Sensibilidad del modelo: \", sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
